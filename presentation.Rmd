---
title: "Introdução ao GAMLSS"
author: "Victor Dalla, Jordão Bragantini"
output: 
  beamer_presentation:
    fig_crop: false
header-includes:
  - \usepackage[brazil, english, portuguese]{babel}
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage[fixlanguage]{babelbib}

  - \usepackage{graphicx}
  - \usepackage{wrapfig}
  - \usepackage{pdfpages}
  
  - \usepackage{amsfonts}
  - \usepackage{amssymb}
  - \usepackage{amsmath}
  
  - \usepackage{subcaption}
  - \usepackage{booktabs}
  - \usepackage{caption}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  results = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE
  )
options(
  OutDec = ",", 
  digits = 3, 
  knitr.table.format = "latex", 
  xtable.comment = FALSE
  )
```

```{r libs}
library(gamlss)
library(magrittr)
library(ggplot2)
library(broom)
library(knitr)
library(dplyr)
```

```{r loading data}
df <- gamlss.data::rent99 %>% as_tibble() %>% 
  dplyr::select(rent, area, yearc, location, cheating)
```



# Motivação: Aluguel de imóveis em Munique

- Pesquisa realizada em 1999 em Munique (Alemanha) onde foram amostrados 1969 novos contratos de aluguéis dos quatro anos anteriores
- A variável resposta *rent* ($\mathbf{Y}$) é o valor mensal do aluguel (em Marcos Alemães)
- As variáveis explicativas são:
    - *area* ($\mathbf{x}_{1}$): Área em metros quadrados dos imóveis
    - *yearc* ($\mathbf{x}_{2}$): Ano de construção.
    - *cheating* ($\mathbf{x}_{3}$): Contém aquecedor? Sim (0) e não (1)
    - *location* ($\mathbf{x}_{4}$): Localização: abaixo da média (1), média (2) ou acima da média (3)

----

```{r descriptive_analysis}
par(mfrow=c(2,2))
plot(rent ~ ., data = df, col=rgb(0.5,0.5,0.5, 0.5), pch=21, cex=0.8)
```

---

- Modelo Linear Simples

$$
Y_{i} = \beta_{0} + \beta_{1} x_{i 1} + \beta_{2} x_{i 2} + \beta_{3} x_{i 3} + \beta_{4} x_{i 4} + \epsilon_{i}, \epsilon_{i} \stackrel{\text{ind}}{\sim} \mathcal{N}\left(0, \sigma^{2}\right)
$$

- Problemas:
    - Heterocedasticidade
    - Relação complexa (talvez não linear) entre as variáveis e suas interações
    - Assimetria positiva da variável resposta

---

## Modelo Linear Simples: Resultados

```{r normal_model}
normal_model <- gamlss(rent ~ area + yearc + location + cheating, family=NO, trace=F, data=df)
```

\begin{table}[]
\centering
\caption{}
\label{tab:model_comp}
\begin{tabular}{lllll}
\hline
\multicolumn{1}{c}{Parâmero} & Termo       & Estimativa & Erro Padrão                & p-valor          \\ \hline
mu                           & (Intercept) & -4009,45   & 249,89                     & \textless{}0.001 \\
mu                           & area        & 5,19       & 0,11                       & \textless{}0.001 \\
mu                           & yearc       & 2,04       & 0,13                       & \textless{}0.001 \\
mu                           & location2   & 49,88      & 5,39                       & \textless{}0.001 \\
mu                           & location3   & 131,62     & 16,55                      & \textless{}0.001 \\
mu                           & cheating1   & 120,11     & 9,04                       & \textless{}0.001 \\
sigma                        & (Intercept) & 4,96       & 0,01                       & \textless{}0.001 \\ \hline
\end{tabular}
\end{table}

---

```{r}
# par(mfrow=c(2,2))
# term.plot(normal_model, data = df, se = T, partial.resid = T,
#           ask = F, col.res = rgb(0.7, 0.7, 0.7,0.3))
```

```{r}
plot(
  normal_model, summaries = F, 
  parameters = par(
    mfrow=c(2,2), mar=par("mar")+c(0,1,0,0), 
    col=rgb(0.5,0.5,0.5, 0.5), pch=21, cex=0.8
  ))
```

---


# GAMLSS

## Definição

Sejam $\boldsymbol{\theta} = (\theta_1, ..., \theta_p)'$ os parâmetros da função de densidade (probabilidade) $f(y | \boldsymbol{\theta})$ computável e sua primeira derivada também, e sejam $y_i | \boldsymbol{\theta}, i = 1, ..., n$ respostas independentes.

Sejam $g_k, k = 1, ..., p$ funções de ligação conhecidas que relacionam os parâmetros com as observações. O modelo GAMLSS é:

\[
g_{k}\left(\boldsymbol{\theta}_{k}\right)=\boldsymbol{\eta}_{k}=\mathbf{X}_{k} \boldsymbol{\beta}_{k}+\sum_{j=1}^{J_{k}} \mathbf{Z}_{j k} \boldsymbol{\gamma}_{j k}
\]

- $\boldsymbol{\theta}_k = (\theta^1, ..., \theta^n)'$ e $\boldsymbol{\eta}_k$ (preditores) são vetores de tamanho $n$
- $\mathbf{X}_k$ são matrizes $n \times J_k^\prime$ de planejamento fixas e $\boldsymbol{\beta}_k$ são vetores de parâmetros de tamanho $J_k^\prime$
- $\mathbf{Z}_{j k}$ são matrizes $n \times q_{j k}$ de planejamento fixas e $\boldsymbol{\gamma}_{j k}$ é uma v.a. de dimensão $q_{j k}$
- Observação: $J_k^, J_k\prime$ e $q_{j k}$ são determinados pela quantidade e definição das matrizes de planejamento

---

- Modelos Aditivos para Localização, Escala e Forma (GAMLSS em inglês) foi introduzido por Rigby & Stasinopoulos (2001, 2005) e Akantziliotou \textit{et al.} (2002)
- Mais gerais:
  - A família de funções de densidade (probabilidade) para a resposta é mais geral que a família exponencial
  - É possível modelar todos os parâmetros da distribuição de $\mathbf{Y}$ de forma paramétrica, não paramétrica (suavizadores) ou por efeitos aleatórios

- Geralmente são considerados no máximo quatro parâmetros: $\boldsymbol{\theta} = (\boldsymbol{\mu}, \boldsymbol{\sigma}, \boldsymbol{\nu}, \boldsymbol{\tau})$ sendo o primeiro de localização, o segundo de escala e os restantes de forma (assimetria e curtose, por exemplo).
- O modelo pode ser reduzido para $g_{k}\left(\boldsymbol{\theta}_{k}\right) = \boldsymbol{\eta}_{k} = \mathbf{X}_{k} \boldsymbol{\beta}_{k}$

---

## Diagnóstico

 - Resíduo quantílitico normalizado (resposta contínua): $\hat{r}_i = \Phi^{-1}(\hat{u}_i$, onde $\Phi^{-1}$ é a função quantil da normal padrão, $\hat{u}_i = F(y|\hat{\boldsymbol{\theta}})$ são os resíduos quantílicos e $F$ é a fda do modelo proposto para $Y$.

 - Segundo Stasinopoulos \textit{et. al} (2017, pg 419), o resíduo quantílitico normalizado tem sempre distribuição normal padrão quando o modelo para $Y$ é correto.

-  Portanto, as ferramentas de diagnóstico do modelo serão as mesmas do caso normal (gráfico de densidade e QQ-plot), permitindo uma comparação direta entre os modelos.


<!-- ## Inferência RESUMIR -->

<!-- - O devio global de um modelo GAMLSS do tipo $g_{k}\left(\boldsymbol{\theta}_{k}\right) = \boldsymbol{\eta}_{k} = \mathbf{X}_{k} \boldsymbol{\beta}_{k}$ é $\mathrm{GD} = -2\ell(\hat{\boldsymbol{\theta}})$, onde $\hat{\boldsymbol{\theta}}$ é a estimativa de $\boldsymbol{\theta}$ e $\ell=\sum_{i=1}^{n} \log \left\{f\left(y^{i} | \boldsymbol{\theta}^{i}\right)\right\}$ -->
<!-- - Os graus de liberdade do erro são $\mathrm{df}_{\mathrm{e}} = n - \sum_{k=1}^{p} \mathrm{df}_{\theta_{k}}$, onde $\mathrm{df}_{\theta_{k}}$ são os graus de liberdade nos modelos preditores de $\theta_k, k = 1, ..., p$ -->
<!-- - Sejam $\mathcal{M}_0$ e $\mathcal{M}_1$ modelos GAMLSS de desvios globais $\mathrm{GD}_0$ e $\mathrm{GD}_1$ e graus de liberdade do erro $\mathrm{df}_{\mathrm{e0}}$ e $\mathrm{df}_{\mathrm{e1}}$, em que $\mathcal{M}_0$ está encaixado em $\mathcal{M}_1$ -->

<!-- --- -->

<!-- - $\Lambda = \mathrm{GD}_0 - \mathrm{GD}_1$ é a estatística do teste (de razão de verossimilhança generalizado) que testa $H_0:$ o modelo $\mathcal{M}_0$ é mais verossímel \textit{vs} $H_1:$ o modelo $\mathcal{M}_1$ é mais verossímel -->
<!-- - Sob condições de regularidade, $\Lambda$ tem distribuição assintótica $\chi^{2}$ de graus de liberdade $\mathrm{df}_{\mathrm{e0}} - \mathrm{df}_{\mathrm{e1}}$ -->
<!-- - É possível testar $H_0: \beta_{j k} = \beta_{j k}^\prime$ contra $H_1: \beta_{j k} \neq \beta_{j k}^\prime$ tomando $\mathcal{M}_1$ como o modelo ajustado e $\mathcal{M}_0$ como o mesmo modelo com $\beta_{j k} = \beta_{j k}^\prime$ (desse modo $\mathrm{df}_{\mathrm{e0}} - \mathrm{df}_{\mathrm{e1}} = 1$) -->
<!-- - É possível calcular um intervalo de confiança de $1 - \alpha$ de confiança para $\beta_{j k}$ através de um \textit{profiling} em $\beta_{j k}$: o intervalo é consitituído de todos os $\beta_{j k}^\prime$ tais que o teste acima falha em rejeitar $H_0$, sendo $\alpha$ o nível de significância do teste -->

---

## Modelando localização e escala por GAMLSS

$$
\begin{aligned} 
  \mathbf{Y} & \stackrel{\mathrm{ind}}{\sim} \text{Gamma}(\boldsymbol{\mu}, \boldsymbol{\sigma}), \quad f(y ; \mu, \sigma^{2})=\frac{y^{1 / \sigma^{2}-1} \exp \left(-\frac{y}{\sigma^{2} \mu}\right)}{(\sigma^{2} \mu)^{(1 / \sigma^{2})} \Gamma(1 / \sigma^{2})} \\ 
  \log(\boldsymbol{\mu}) = \boldsymbol{\eta}_{1} & = \beta_{0} + \beta_{1} x_{i 1} + \beta_{2} x_{i 2} + \beta_{3} x_{i 3} + \beta_{4} x_{i 4} \\ 
  \log(\boldsymbol{\sigma}) = \boldsymbol{\eta}_{2} & = \log(\boldsymbol{\sigma}) = \beta_{0} + \beta_{1} \mathbf{x}_{1} + \beta_{2} \mathbf{x}_{2} + \beta_{3} \mathbf{x}_{3} + \beta_{4} \mathbf{x}_{4}
\end{aligned}
$$

---

## GAMLSS: Resultados

```{r}
gamma_model <- gamlss(rent ~ area + yearc + location + cheating,
             sigma.fo = ~ area + yearc + location + cheating,
             family=GA, trace=F, data=df)
```

\begin{table}[]
\centering
\caption{}
\label{tab:model_comp}
\begin{tabular}{lllll}
\hline
\multicolumn{1}{c}{Parâmero} & Termo       & Estimativa & Erro Padrão                          & p-valor          \\ \hline
mu                           & (Intercept) & -5,164     & 0,527                                & \textless{}0,001 \\
mu                           & area        & 0,011      & \textless{}0,001                     & \textless{}0,001 \\
mu                           & yearc       & 0,005      & \textless{}0,001                     & \textless{}0,001 \\
mu                           & location2   & 0,097      & 0,011                                & \textless{}0,001 \\
mu                           & location3   & 0,203      & 0,041                                & \textless{}0,001 \\
mu                           & cheating1   & 0,281      & 0,024                                & \textless{}0,001 \\
sigma                        & (Intercept) & 10,116     & 1,220                                & \textless{}0,001 \\
sigma                        & area        & 0,001      & 0,001                                & 0,007            \\
sigma                        & yearc       & -0,006     & 0,001                                & \textless{}0,001 \\
sigma                        & location2   & 0,081      & 0,026                                & 0,002            \\
sigma                        & location3   & 0,244      & 0,080                                & 0,002            \\
sigma                        & cheating1   & -0,200     & 0,044                                & \textless{}0,001 \\ \hline
\end{tabular}
\end{table}

---

```{r}
# par(mfrow=c(2,2))
# term.plot(gamma_model, data = df, se = T, partial.resid = T,
#           ask = F, col.res = rgb(0.7, 0.7, 0.7,0.3))
term.plot(gamma_model, what = "mu", se = TRUE, pages=1, ask=FALSE)
```

---

```{r}
term.plot(gamma_model, what = "sigma", se = TRUE, pages=1, ask=FALSE)
```

---

```{r}
plot(
  gamma_model, summaries = F, 
  parameters = par(
    mfrow=c(2,2), mar=par("mar")+c(0,1,0,0), 
    col=rgb(0.5,0.5,0.5, 0.5), pch=21, cex=0.8
  ))
```

---

## Comparação

```{r}
compare_AIC <- AIC(normal_model, gamma_model)
compare_BIC <- BIC(normal_model, gamma_model)
```

\begin{table}[]
\centering
\caption{}
\label{tab:model_comp}
\begin{tabular}{lllr}
\hline
\multicolumn{1}{c}{Modelo} & AIC   & BIC   & \multicolumn{1}{l}{GL} \\ \hline
Gama                       & 38527 & 39370 & 12                     \\
Normal                     & 39328 & 38599 & 7                      \\ \hline
\end{tabular}
\end{table}

---

## Modelando localização, escala e forma

$$
\begin{aligned} \mathbf{Y} & \stackrel{\mathrm{ind}}{\sim} \mathcal{D}(\boldsymbol{\mu}, \boldsymbol{\sigma}, \boldsymbol{\nu}) \\ \boldsymbol{\eta}_{1} &=g_{1}(\boldsymbol{\mu})=\mathbf{X}_{1} \boldsymbol{\beta}_{1} \\ \boldsymbol{\eta}_{2} &=g_{2}(\boldsymbol{\sigma})=\mathbf{X}_{2} \boldsymbol{\beta}_{2} \\ \boldsymbol{\eta}_{3} &=g_{3}(\boldsymbol{\nu})=\mathbf{X}_{3} \boldsymbol{\beta}_{3} \end{aligned}
$$

$$
\begin{aligned} \mu =  \ & \beta_{10} + \beta_{11} \ \texttt {area} + \beta_{12} \ \texttt {yearc} + \beta_{13} \ \texttt {(if cheating = 1)} + \\ & \beta_{14} \ \texttt {(if location = 2)}  + \beta_{15} \ \texttt {(if location = 3)} \\ 
\log (\sigma) = \ & \beta_{20} + \beta_{21} \ \texttt {area} + \beta_{22} \ \texttt {yearc} + \beta_{23} \ \texttt {(if cheating = 1)} + \\ & \beta_{24} \ \texttt {(if location = 2)}  + \beta_{25} \ \texttt {(if location = 3)} \\ 
\nu = & \ \beta_{30} + \beta_{31} \ \texttt {yearc} \end{aligned}
$$

---

```{r}
m3 <- gamlss(rent ~ area + yearc + location + cheating,
             sigma.fo = ~ area + yearc + location + cheating,
             nu.fo = ~ yearc,
             family = BCCGo, trace = F, data = df)

# par(mfrow=c(2,2))
# term.plot(m3, data = df, se = T, partial.resid = T,
#           ask = F, col.res = rgb(0.7, 0.7, 0.7,0.3))
term.plot(gamma_model, se = TRUE, pages=1, ask=FALSE)
```

---

```{r}
plot(m3, bg='white')
```

---

`r summary(m3) %>% tidy() %>% kable() `

---

organizar e ordenar

`r AIC(normal_model, gamma_model, m3) %>% kable()`

`r BIC(normal_model, gamma_model, m3) %>% kable()`

